# Import from standard library
import logging
import datetime
import json
import math

# Import from third-party
from flask import Flask, render_template, json, request, jsonify, redirect, session
import pytz

# Import local files
import DAO.db_connect as db_connect
from config.config import ElasticConfig

DEFAULT_SORT = "created_date:desc"

def scan_overview():
    try:
        es = db_connect.connect_elasticsearch()
        try:
            # Process sort and body from arguments
            search_query = request.args.get('q') or ''
            _search_query = ' '.join('*'+_+'*' for _ in search_query.split(' '))
            paging_from = int(request.args.get('page') or 1)
            paging_size = ElasticConfig.DEFAULT_PAGE_SIZE
            if 'size' in request.args:
                paging_size = int(request.args.get('size'))
                session['paging_size'] = paging_size
            elif 'paging_size' in session:
                paging_size = session['paging_size']
                
            raw_sort = request.args.get('sort')
            sort_query = DEFAULT_SORT if raw_sort is None else DEFAULT_SORT if raw_sort == 'init_desc' else "created_date:asc"
            query_body = {
                            "_source": ["target", "created_date","next_run_at", "next_run_at", "run_interval", "scan_type", "scanned_time", "name", "description", "isStopped"],
                            "from": (paging_from - 1) * paging_size,
                            "size": paging_size,
                            "query": {
                                "bool": {
                                    "filter": {
                                        "bool": {
                                            "must_not": [
                                                { "match": { "isDeleted": True}}
                                            ],
                                            "should": [
                                            {
                                                "query_string": {
                                                "fields": ["target"],
                                                "query": _search_query
                                                }
                                            }
                                            ]
                                        }
                                    }
                                }
                            }
                        }
            # Process data
            rawData = es.search(
                index=ElasticConfig.SCAN_INDEX, body=query_body, sort=sort_query)

            processed_data = processScan(rawData)
                
            root_scan_id = ''
            for data in processed_data['records']:
                root_scan_id += data["id"] + ' '

            summary_result = getSummaryResult(root_scan_id)

            for i in range(len(processed_data['records'])):
                data = processed_data['records'][i]
                processed_data['records'][i]['summary_result'] = summary_result[processed_data['records'][i]['id']]

            paging_total = processed_data['total']
            paging = {
                "paging_from": paging_from,
                "paging_size": paging_size,
                "paging_total": paging_total,
                "left_page": max(paging_from - 2, 1),
                "right_page": min(max(paging_from - 2, 1) + 4, math.ceil(paging_total / paging_size))
            }
        except:
            logging.exception(msg="Fail")
    except:
        logging.exception(msg="Fail")
    session['module'] = "scan"
    session['overview'] = True
    return render_template('scan.html', response=processed_data, search_query=search_query, sorting=sort_query, paging = paging)

def processScan(rawData):
    try:
        UTC7 = pytz.timezone('Asia/Ho_Chi_Minh')
        processing_data = rawData['hits']
        result = {}
        result['total'] = processing_data['total']
        result['records'] = []
        for hit in processing_data['hits']:
            _source = hit['_source']
            _source["id"] = hit.get('_id')
            _source['created_date'] = str(datetime.datetime.fromtimestamp(
                    int(_source.get('created_date')), tz=UTC7))
            _source['next_run_at'] = str(datetime.datetime.fromtimestamp(
                    int(_source.get('next_run_at')), tz=UTC7))     
            result['records'].append(_source)

        return result

    except:
        logging.exception(msg="No validated jsonified data to be processed!")

def getSummaryResult(root_scan_id):
    result = dict()
    list_root_scan_id = root_scan_id.split(' ')
    try:
        resultAcunetix = getDataFromElastic(root_scan_id)
        for root_scan in list_root_scan_id:
            result[root_scan] = {
                "low" : 0,
                "informational" : 0,
                "high" : 0,
                "medium" : 0
            }

            result[root_scan]['informational'] += resultAcunetix.get(root_scan, dict()).get('informational', 0)
            result[root_scan]['low'] += resultAcunetix.get(root_scan, dict()).get('low', 0)
            result[root_scan]['medium'] += resultAcunetix.get(root_scan, dict()).get('medium', 0)
            result[root_scan]['high'] += resultAcunetix.get(root_scan, dict()).get('high', 0)
    except:
        logging.exception(msg="Something went wrong!")
    return result

def getDataFromElastic(root_scan_id):
    result = dict()
    try:
        es = db_connect.connect_elasticsearch()
        query_body = {
                    "query": {
                        "bool": {
                            "filter": {
                                "bool": {
                                    "should": [
                                    {
                                        "query_string": {
                                        "fields": ["root_scan_id"],
                                        "query": root_scan_id
                                        }
                                    }
                                    ]
                                }
                            }
                        }
                    },
                    "size": 0,
                    "aggs": {
                        "group_by_root_scan_id": {
                        "terms": {
                            "field": "root_scan_id.keyword",
                            "size": ElasticConfig.MAX_SIZE_AGGS
                        },
                        "aggs": {
                            "informational": {
                                "sum": {
                                    "field": "vuln_stats.informational"
                                }
                            },
                            "low": {
                                "sum": {
                                    "field": "vuln_stats.low"
                                }
                            },
                            "medium": {
                                "sum": {
                                    "field": "vuln_stats.medium"
                                }
                            },
                            "high": {
                                "sum": {
                                    "field": "vuln_stats.high"
                                }
                            }
                        }
                        }
                    }
                    }
        rawData = es.search(index=[ElasticConfig.ACUNETIX_SUMMARY_INDEX , ElasticConfig.CVESEARCH_INDEX, ElasticConfig.NESSUS_INDEX], body=query_body)
        processing_data = rawData['aggregations']["group_by_root_scan_id"]["buckets"]
        for data in processing_data:
            res = {
                "low" : int(data['low']['value']),
                "informational" : int(data['informational']['value']),
                "high" : int(data['high']['value']),
                "medium" : int(data['medium']['value'])
            }
            result[data.get('key')] =  res

    except:
        logging.exception(msg="Something went wrong!")
    return result