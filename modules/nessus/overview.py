# Import from standard library
import logging
import datetime
import math

# Import from third-party
from flask import Flask, render_template, json, request, jsonify, session
import pytz

# Import local files
import DAO.db_connect as db_connect
from config.config import ElasticConfig


def nessus_overview():
    try:
        es = db_connect.connect_elasticsearch()
        try:
            # Process sort and body from arguments
            search_query = request.args.get('q') or ''
            _search_query = ' '.join(
                '*'+_+'*' for _ in search_query.split(' '))
            paging_from = int(request.args.get('page') or 1)
            paging_size = ElasticConfig.DEFAULT_PAGE_SIZE
            if 'size' in request.args:
                paging_size = int(request.args.get('size'))
                session['paging_size'] = paging_size
            elif 'paging_size' in session:
                paging_size = session['paging_size']
            sort = request.args.get('sort')
            index = request.args.get('index')
            if index is None:
                index = "scanstat.startTime"
            if sort is None:
                sort = "desc"
            sort_query = generateSortQuery(sort, index)
            query_body = {
                "_source": ["target", "vuln_stats", "scanstat", "hostname", "ports", "scan_id", "scan_name", "root_scan_id"],
                "from": (paging_from - 1) * paging_size,
                "size": paging_size,
                "query": {
                    "bool": {
                        "filter": {
                            "bool": {
                                "should": [
                                    {
                                        "query_string": {
                                            "fields": ["target", "hostname", "scan_id", "scan_name"],
                                            "query": _search_query
                                        }
                                    }
                                ]
                            }
                        }
                    }
                }
            }
            # Process data
            rawData = es.search(index=ElasticConfig.NESSUS_INDEX,
                                body=query_body, sort=sort_query)
            processed_data = processNessus(rawData)
            paging_total = processed_data['total']
            paging = {
                "paging_from": paging_from,
                "paging_size": paging_size,
                "paging_total": paging_total,
                "left_page": max(paging_from - 2, 1),
                "right_page": min(max(paging_from - 2, 1) + 4, math.ceil(paging_total / paging_size))
            }
            if sort == "desc":
                sort = "asc"
            else:
                sort = "desc"
        except:
            logging.exception(msg="Fail")
    except:
        logging.exception(msg="Fail")
    session['module'] = "nessus"
    session['overview'] = True
    return render_template('nessus.html', response=processed_data, search_query=search_query, sorting=sort, index=index, paging=paging)


def generateSortQuery(sort, index):
    sort_query = ""
    if index == '1':
        sort_query = "target.keyword" + ":" + sort
    elif index == '2':
        sort_query = "hostname.keyword" + ":" + sort
    elif index == '3':
        sort_query = "scanstat.startTime" + ":" + sort
    elif index == '4':
        sort_query = "scanstat.duration" + ":" + sort
    elif index == '5':
        sort_query = "scan_id.keyword" + ":" + sort
    elif index == '6':
        sort_query = "scan_name.keyword" + ":" + sort
    elif index == '7':
        sort_query = "vuln_stats.high:{},vuln_stats.medium:{},vuln_stats.low:{},vuln_stats.informational:{}".format(sort, sort, sort, sort)

    return sort_query


def processNessus(rawData):
    try:
        UTC7 = pytz.timezone('Asia/Ho_Chi_Minh')
        processing_data = rawData['hits']
        result = {}
        # Backward version of elasticSearch compatitive
        if type(processing_data['total']) == dict:
            result['total'] = processing_data['total']['value']
        else:
            result['total'] = processing_data['total']
        result['records'] = []
        for hit in processing_data['hits']:
            _source = hit['_source']
            _source["id"] = hit.get('_id')
            _source['init_time'] = str(datetime.datetime.fromtimestamp(
                int(_source.get('scanstat').get("startTime")), tz=UTC7))
            _source['scan_time'] = int(_source.get('scanstat').get("duration"))
            result['records'].append(_source)

        return result

    except:
        logging.exception(msg="No validated jsonified data to be processed!")
